---
title: "ENTREGA 2"
date: today
date-format: "DD MMMM, YYYY"
author: 
  Mathias
abstract:
    Métodos Estadísticos para la Regresión y la Clasificación
abstractspacing: double
appendix: false
fontfamily: libertine
monofont: inconsolata
monofontoptions: scaled=.95
fontsize: 12pt
geometry: 
  - top=2cm
  - bottom=2cm
  - left=2cm
  - right=2cm
urlcolor: darkblue
highlight-style: arrow
format: 
    pdf:
      toc: true
      number-sections: true
      colorlinks: true
---

# Ejercicio 2

Datos de Entrenamiento

| Lluvia (mm)  | Rendimiento (ton/ha) |
|--------------|----------------------|
| 206          | 29                   |
| 188          | 25                   |
| 219          | 31                   |
| 372          | 25                   |
| 345          | 29                   |
| 231          | 30                   |
| 203          | 26                   |
| 170          | 23                   |
| 55           | 12                   |
| 91           | 15                   |
| 292          | 28                   |
| 141          | 24                   |
| 129          | 23                   |
| 170          | 22                   |
| 324          | 30                   |

Datos de Validación

| Lluvia (mm)  | Rendimiento (ton/ha) |
|--------------|----------------------|
| 213          | 30                   |
| 80           | 16                   |
| 391          | 25                   |
| 250          | 26                   |
| 57           | 9                    |
| 303          | 28                   |
| 263          | 28                   |
| 157          | 25                   |
| 72           | 13                   |
| 157          | 23                   |
| 188          | 26                   |
| 216          | 25                   |
| 362          | 28                   |
| 283          | 33                   |
| 308          | 30                   |

## Correr una regresión lineal para predecir el rendimiento y en función de la lluvia $x$.

La regresión lineal se modela mediante la siguiente ecuación

$$
y = \beta_0 + \beta_1 \cdot x
$$

Donde $y$ es el rendimiento $(ton/ha)$, $x$ es la cantidad de lluvia $(mm)$, $beta_0$ es la intersección y $beta_1$ la pendiente de la recta.

```{r}
# Datos de entrenamiento
train_data <- data.frame(
  lluvia = c(206, 188, 219, 372, 345, 231, 203, 170, 55, 91, 292, 141, 129, 170, 324),
  rendimiento = c(29, 25, 31, 25, 29, 30, 26, 23, 12, 15, 28, 24, 23, 22, 30)
)

# Modelo de regresión lineal
modelo_lineal <- lm(rendimiento ~ lluvia, data = train_data)

# Resumen del modelo
summary(modelo_lineal)
```

El coeficiente de la variable lluvia es $\beta_1 = 0.04345$, siendo en promedio que por cada milimetro de lluvia, se espera un aumento en el rendimiento de $0.04345$ toneladas por hectarea. La intersección $\beta_0 = 15.71595$, en el caso de que la lluvia acumulada sea 0, el modelo predice 15.72 toneladas por hectárea. Asimismo, el $\text{p-value}$ indicando que hay una relacion significativa entre la lluvia y el rendimiento.

## Comparar el MSE en entrenamiento, validación y CV.

El MSE mide la calidad del ajuste del modelo, usando la medai del error cuadratico entre lo predicho y lo observado. Se calcula como $\text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2$, siendo $y_i$ valores observados y $hat{y}_i$ los valores predichos. Entonces 

```{r}

# Datos de validación
validacion_data <- data.frame(
  lluvia = c(213, 80, 391, 250, 57, 303, 263, 157, 72, 157, 188, 216, 362, 283, 308),
  rendimiento = c(30, 16, 25, 26, 9, 28, 28, 25, 13, 23, 26, 25, 28, 33, 30)
)

# Función para calcular el MSE
calcular_mse <- function(observado, predicho) {
  mean((observado - predicho)^2)
}

# Predicciones en el conjunto de entrenamiento y validación
predicciones_train <- predict(modelo_lineal, newdata = train_data)
predicciones_validacion <- predict(modelo_lineal, newdata = validacion_data)

# MSE en entrenamiento y validación
mse_train <- calcular_mse(train_data$rendimiento, predicciones_train)
mse_validacion <- calcular_mse(validacion_data$rendimiento, predicciones_validacion)

cat("MSE en entrenamiento: ", mse_train, "\n")
cat("MSE en validación: ", mse_validacion, "\n")

```

El MSE en el entrenamiento es menor que el MSE en validacion, puede estar ocurriendo un sobreajuste del modelo. Este problema podria abordarse de varias formas como aplicar tecnicas de regularizacion, mas datos de entrenamiento y cross-validation, de esta forma se reduciria el sobreajuste y el modelo tendria generalizaria mejor.

## Determinar el grado óptimo en caso de aplicar una regresión polinomial.

La regresión polinomial se ajusta con la siguiente ecuación $y = \beta_0 + \beta_1 \cdot x + \beta_2 \cdot x^2 + \dots + \beta_d \cdot x^d$. Utilizando la funcion lm() de R, podemos ajustar modelos polinomiales de diferentes grados y comparar el MSE.

```{r}
# Regresion polinomial para diferentes grados
grados <- 1:5  # Probaremos con grados 1 a 5
mse_polynomial <- numeric(length(grados))

for (grado in grados) { # Recorro loop con cada uno de los grados aplicando lm() y calculando MSE
  modelo_pol <- lm(rendimiento ~ poly(lluvia, grado), data = train_data)
  predicciones_pol <- predict(modelo_pol, newdata = train_data)
  mse_polynomial[grado] <- calcular_mse(train_data$rendimiento, predicciones_pol)
}

cat("MSE para diferentes grados: \n")
print(mse_polynomial)

```

A medida que se aumenta el grado, el MSE disminuye hasta que se estabiliza para grados 3, 4 y 5. Esto sugiere que un polinomio de grado 3 sea el mas adecuado, ya que logra un MSE bajo sin agregar complejidad al modelo.


## Hallar el valor de $\lambda$ óptimo para la regresión polinomial de grado 5 con regularización.

En la regresión polinomial con regularización, aplicamos el valor de λλ para controlar la penalización sobre los coeficientes. La fórmula de Ridge es

$$
\text{Minimizar} \left( \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 + \lambda \sum_{j=1}^{d} \beta_j^2 \right)
$$

Siendo $y_i$ valores observados, $\hat{y}_i$ valores predichos y $\lambda$ el parametro de regularizacion.

```{r}
#Cargar la biblioteca glmnet
library(glmnet)

#crear matriz de caracteristicas para el polinomio de grado 5 en los datos de entrenamiento
x_train <- as.matrix(poly(train_data$lluvia, 5, raw = TRUE))
y_train <- train_data$rendimiento                 # variable dependiente

# crear matriz de caracteristicas para los datos de validacioon
x_validacion <- as.matrix(poly(validacion_data$lluvia, 5, raw = TRUE))

#ajusto modelo de Ridge (regresion_L2) para un polinomio de grado 5
modelo_ridge <- glmnet(x_train, y_train, alpha = 0, lambda = 0.1)

#Predicciones en los datos de validacion
predicciones_ridge <- predict(modelo_ridge, newx = x_validacion)

#Se calcula el MSE para Ridge
mse_ridge <- calcular_mse(validacion_data$rendimiento, predicciones_ridge)

#imprimir resultado del MSE para Ridge
cat("MSE para Ridge con lambda = 0.1: ", mse_ridge, "\n")

```

El MSE de 5.7 refleja el desempeño del modelo en el conjunto de validación. Un MSE más bajo indica una mejor prediccion del modelo en los datos de validacion. La regularizacion reduce la posibilidad de sobreajuste, como en modelos complejos, perdiendo precision.


# Ejercicio 6: Árbol de decisión para clasificar variedades de tomates

| Dulzor | No. tomates | Cherry	| Perita |
|--------|-------------|--------|--------|
| Alto 	 |     55      |	 30	  |  25    |
| Bajo	 |     35	     |   15	  |  20    |


| Dulzor  | No. tomates | Cherry	| Perita |
|---------|-------------|---------|--------|
| Pequeño |     60      |	 40	    |  20    |
| Grande	|     30	    |   5	    |  25    |


## Calcule la impureza de Gini esperada para cada una de las divisiones

La impureza de Gini esperada para una división se calcula con la siguiente ecuacion

$$
\frac{N(t_L)}{N(t)}\times H(y;S_L)+\frac{N(t_R)}{N(t)}\times H(y;S_R)
$$

donde $N(t_L)$ es el número de observaciones en el nodo izquierdo, $N(t_R)$ es el numero de observaciones en el nodo derecho, $H(y; S_L)$ y $H(y; S_R)$ son las impurezas de Gini de los nodos izquierdo y derecho.

Calculamos la impureza de Gini esperada para cada division. El Gini esperado para la division de Dulzor es

```{r}
# Tamaño de cada nodo
N_root <- 90
N_Alto <- 55
N_Bajo <- 35

# Calcular impurezas de Gini para cada nodo hoja
Gini_Alto <- 1 - ((30 / 55)^2 + (25 / 55)^2)
Gini_Bajo <- 1 - ((15 / 35)^2 + (20 / 35)^2)

```

El Gini esperado para el dulzor es 
$$
\text{Gini Dulzor} = \frac{55}{90} \times 0.496 + \frac{35}{90} \times 0.489 = 0.494
$$


El Gini esperado para la division de tamaño es

```{r}
# Tamaño de cada nodo
N_Pequeno <- 60
N_Grande <- 30

# Calcular impurezas de Gini para cada nodo hoja
Gini_Pequeno <- 1 - ((40 / 60)^2 + (20 / 60)^2)
Gini_Grande <- 1 - ((5 / 30)^2 + (25 / 30)^2)

# Gini esperado para la división por Tamaño
Gini_Tamano <- (N_Pequeno / N_root) * Gini_Pequeno + (N_Grande / N_root) * Gini_Grande
Gini_Tamano

```


## ARBOL
```{r}
library(dplyr)
library(rpart)       # Para construir árboles de decisión
library(rpart.plot)  # Para graficar árboles de decisión
library(rattle)

# Crear un dataframe con los datos
datos <- data.frame(
  Atributo = rep(c("Dulzor_Alto", "Dulzor_Bajo", "Tamano_Pequeno", "Tamano_Grande"), each = 2),
  Clase = c("Cherry", "Perita", "Cherry", "Perita", "Cherry", "Perita", "Cherry", "Perita"),
  Count = c(30, 25, 15, 20, 40, 20, 5, 25)
)

datos$Atributo <- factor(datos$Atributo)
datos$Clase <- factor(datos$Clase)

# Entrenar el árbol de decisión utilizando el argumento 'weights' con la columna Count
arbol <- rpart(
  formula = Clase ~ Atributo,
  data = datos %>% filter(Atributo %in% c("Dulzor_Alto", "Dulzor_Bajo")),
  method = 'class',
  weights = Count,
  control = rpart.control(minsplit = 2, 
                          minbucket = 1, 
                          cp = 0.05)
)

# Graficar el árbol utilizando fancyRpartPlot
png("tree_plot.png", width = 800, height = 600)
fancyRpartPlot(arbol)
dev.off()

```

![Arbol de decision dulzor](tree_plot.png)


```{r}
# Datos para árbol de decisión basado en Tamaño
datos_tamano <- data.frame(
  Tamano = c("Pequeño", "Pequeño", "Grande", "Grande"),
  Clase = c("Cherry", "Perita", "Cherry", "Perita"),
  Count = c(40, 20, 5, 25)
)

datos_tamano$Tamano <- factor(datos$Tamano)
datos_tamano$Clase <- factor(datos$Clase)

# Entrenar el árbol de decisión utilizando el argumento 'weights' con la columna Count
arbol_tamano <- rpart(
  formula = Clase ~ Tamano,
  data = datos %>% filter(Tamano %in% c("Grande", "Pequeño")),
  method = 'class',
  weights = Count,
  control = rpart.control(minsplit = 2, 
                          minbucket = 1, 
                          cp = 0.05)
)

# Graficar el árbol utilizando fancyRpartPlot
png("tree_tamano_plot.png", width = 800, height = 600)
fancyRpartPlot(arbol_tamano)
dev.off()

```

![Arbol de decision tamaño](tree_tamano_plot.png)

## ¿Qué pregunta elegiría en el nodo raíz? Justificar en base a las partes anteriores

Dado que:

    Gini esperado para Dulzor: GiniDulzor=0.4935GiniDulzor​=0.4935
    Gini esperado para Tamaño: GiniTaman˜o=0.3889GiniTaman˜o​=0.3889

Elección de la pregunta en el nodo raíz:

La mejor pregunta en el nodo raíz es:
"¿El tamaño es pequeño o grande?"
Justificación:

    Menor impureza:
    La impureza esperada GiniTaman˜oGiniTaman˜o​ es menor que GiniDulzorGiniDulzor​, lo que indica que el atributo Tamaño produce una división más pura y, por lo tanto, mejor separa las clases (Cherry y Perita).

    Distribución más pura en los nodos hijos:
        División por Tamaño:
            Pequeño: 60 tomates (40 Cherry, 20 Perita). Predicción: Cherry.
            Grande: 30 tomates (5 Cherry, 25 Perita). Predicción: Perita.
        División por Dulzor:
            Alto: 55 tomates (30 Cherry, 25 Perita). Mezcla significativa.
            Bajo: 35 tomates (15 Cherry, 20 Perita). Mezcla significativa.

    Observamos que la división por Tamaño resulta en nodos hijos más homogéneos.

    Optimización de la clasificación:
    Elegir Tamaño como el atributo para dividir maximiza la pureza en los nodos y minimiza la incertidumbre de la clasificación, conforme al criterio de Gini.

## Para el árbol elegido en la parte anterior, calcular el error

Cálculo del error para el árbol seleccionado

El error se calcula como la fracción de observaciones mal clasificadas en el conjunto de entrenamiento.

```{r}
# Supongamos que elegimos Dulzor:
# Nodo Alto: predicción Cherry
# Nodo Bajo: predicción Perita

# Observaciones mal clasificadas
error_dulzor <- (25 + 15) / N_root
error_dulzor

# Para Tamaño:
# Nodo Pequeño: predicción Cherry
# Nodo Grande: predicción Perita

error_tamano <- (20 + 5) / N_root
error_tamano

```

# Ejercicio 3: Análisis de Componentes Principales

En este ejercicio, se realiza un análisis de componentes principales (PCA) sobre una matriz de datos que representa las notas obtenidas por los estudiantes en cinco asignaturas. Los datos están organizados en una tabla donde cada fila corresponde a un estudiante y cada columna a una asignatura:

| Estudiante | Matemática | Física | Música | Dibujo | Id. Español |
|------------|------------|--------|--------|--------|-------------|
| Juan       | 12         | 12     | 10     | 11     | 16          |
| Alina      | 16         | 16     | 16     | 16     | 18          |
| Ana        | 12         | 14     | 22     | 19     | 22          |
| Mónica     | 29         | 29     | 31     | 30     | 16          |
| Daniel     | 28         | 28     | 24     | 24     | 20          |
| Andrés     | 22         | 20     | 11     | 14     | 26          |
| Pedro      | 11         | 14     | 28     | 23     | 20          |
| Valentina  | 26         | 25     | 17     | 19     | 24          |
| Sandra     | 18         | 19     | 25     | 24     | 36          |

### Análisis de Componentes Principales (PCA)

Primero, cargamos los datos en R y realizamos el análisis de componentes principales utilizando la función `prcomp`. Esta función nos permite obtener los componentes principales y evaluar la importancia de cada uno.

```{r}
# Datos de las notas de los estudiantes
datos <- data.frame(
  Matemática = c(12, 16, 12, 29, 28, 22, 11, 26, 18),
  Física = c(12, 16, 14, 29, 28, 20, 14, 25, 19),
  Música = c(10, 16, 22, 31, 24, 11, 28, 17, 25),
  Dibujo = c(11, 16, 19, 30, 24, 14, 23, 19, 24),
  `Id. Español` = c(16, 18, 22, 16, 20, 26, 20, 24, 36)
)

# Realizar PCA
pca <- prcomp(datos, scale. = TRUE)

# Mostrar el resumen del PCA
summary(pca)
```

Calidades de cada componente

La "calidad" de cada componente principal se refiere a la varianza explicada por ese componente. La función summary() nos muestra cuánta varianza es explicada por cada uno de los componentes principales.

La varianza explicada por el componente ii se calcula como:
Varianza explicada del componente i=λi∑j=1pλj
Varianza explicada del componente i=∑j=1p​λj​λi​​

donde λiλi​ es el valor propio (eigenvalue) del componente ii y pp es el número total de componentes.
Contribuciones de cada variable

Las contribuciones de cada variable a los componentes principales se pueden obtener examinando las cargas (loadings) de los componentes, que indican qué tan influyente es cada variable en cada componente.
```{r}
# Cargas (loadings) de los componentes
pca$rotation
```

Calidades y contribuciones de los individuos

Finalmente, las coordenadas de cada individuo en el espacio de los componentes principales nos indican en qué medida cada estudiante contribuye a los componentes principales. Estas coordenadas se obtienen multiplicando la matriz de datos centrados y escalados por las cargas de los componentes.
```{r}
# Coordenadas de los individuos en los componentes principales
pca$x
```

Los valores obtenidos nos permiten visualizar la distribución de los estudiantes en el espacio de los componentes principales, mostrando qué tan lejos o cerca están de los ejes principales.
Visualización de los resultados

Podemos visualizar los primeros dos componentes principales utilizando un gráfico de dispersión.
```{r}
# Graficar los primeros dos componentes principales
library(ggplot2)
pca_data <- as.data.frame(pca$x)
pca_data$Estudiante <- c("Juan", "Alina", "Ana", "Mónica", "Daniel", "Andrés", "Pedro", "Valentina", "Sandra")

ggplot(pca_data, aes(x = PC1, y = PC2, label = Estudiante)) +
  geom_point() +
  geom_text(vjust = 1.5, hjust = 1.5) +
  labs(title = "PCA: Primeros dos Componentes Principales", x = "Componente Principal 1", y = "Componente Principal 2")
```

Conclusiones

El análisis de componentes principales nos permite reducir la dimensionalidad del conjunto de datos, extrayendo los componentes que explican la mayor parte de la varianza. En este caso, los componentes principales nos muestran cómo se distribuyen los estudiantes según sus calificaciones en las distintas asignaturas, ayudándonos a identificar patrones o grupos dentro del conjunto de datos.