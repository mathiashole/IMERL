---
title: "ENTREGA 2"
date: today
date-format: "DD MMMM, YYYY"
author: 
  Mathias
abstract:
    Métodos Estadísticos para la Regresión y la Clasificación
abstractspacing: double
appendix: false
fontfamily: libertine
monofont: inconsolata
monofontoptions: scaled=.95
fontsize: 12pt
geometry: 
  - top=2cm
  - bottom=2cm
  - left=2cm
  - right=2cm
urlcolor: darkblue
highlight-style: arrow
format: 
    pdf:
      toc: true
      number-sections: true
      colorlinks: true
---

# Ejercicio 2: Análisis de Regresión para Predicción de Rendimiento de Papas

Datos de Entrenamiento

| Lluvia (mm)  | Rendimiento (ton/ha) |
|--------------|----------------------|
| 206          | 29                   |
| 188          | 25                   |
| 219          | 31                   |
| 372          | 25                   |
| 345          | 29                   |
| 231          | 30                   |
| 203          | 26                   |
| 170          | 23                   |
| 55           | 12                   |
| 91           | 15                   |
| 292          | 28                   |
| 141          | 24                   |
| 129          | 23                   |
| 170          | 22                   |
| 324          | 30                   |

Datos de Validación

| Lluvia (mm)  | Rendimiento (ton/ha) |
|--------------|----------------------|
| 213          | 30                   |
| 80           | 16                   |
| 391          | 25                   |
| 250          | 26                   |
| 57           | 9                    |
| 303          | 28                   |
| 263          | 28                   |
| 157          | 25                   |
| 72           | 13                   |
| 157          | 23                   |
| 188          | 26                   |
| 216          | 25                   |
| 362          | 28                   |
| 283          | 33                   |
| 308          | 30                   |

## Correr una regresión lineal para predecir el rendimiento y en función de la lluvia x

La regresión lineal se modela mediante la siguiente ecuación:

$$
y = \beta_0 + \beta_1 \cdot x
$$

Donde $y$ es el rendimiento $(ton/ha)$, $x$ es la cantidad de lluvia $(mm)$, $beta_0$ es la intersección y $beta_1$ la pendiente de la recta.

```{r}
# Datos de entrenamiento
train_data <- data.frame(
  lluvia = c(206, 188, 219, 372, 345, 231, 203, 170, 55, 91, 292, 141, 129, 170, 324),
  rendimiento = c(29, 25, 31, 25, 29, 30, 26, 23, 12, 15, 28, 24, 23, 22, 30)
)

# Modelo de regresión lineal
modelo_lineal <- lm(rendimiento ~ lluvia, data = train_data)

# Resumen del modelo
summary(modelo_lineal)
```

## Comparar el MSE en entrenamiento, validación y CV

El MSE se calcula como $\text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2$, siendo $y_i$ valores observados y $hat{y}_i$ los valores predichos. Entonces 

```{r}

# Datos de validación
validacion_data <- data.frame(
  lluvia = c(213, 80, 391, 250, 57, 303, 263, 157, 72, 157, 188, 216, 362, 283, 308),
  rendimiento = c(30, 16, 25, 26, 9, 28, 28, 25, 13, 23, 26, 25, 28, 33, 30)
)

# Función para calcular el MSE
calcular_mse <- function(observado, predicho) {
  mean((observado - predicho)^2)
}

# Predicciones en el conjunto de entrenamiento y validación
predicciones_train <- predict(modelo_lineal, newdata = train_data)
predicciones_validacion <- predict(modelo_lineal, newdata = validacion_data)

# MSE en entrenamiento y validación
mse_train <- calcular_mse(train_data$rendimiento, predicciones_train)
mse_validacion <- calcular_mse(validacion_data$rendimiento, predicciones_validacion)

cat("MSE en entrenamiento: ", mse_train, "\n")
cat("MSE en validación: ", mse_validacion, "\n")

```

Dado los valores obtenidos con MSE de validación cercano al de entrenamiento, como en este caso, sugiere que el modelo tiene un rendimiento adecuado sin un sobreajuste.

## Determinar el grado óptimo en caso de aplicar una regresión polinomial.

La regresión polinomial se ajusta con la siguiente ecuación $y = \beta_0 + \beta_1 \cdot x + \beta_2 \cdot x^2 + \dots + \beta_d \cdot x^d$. Utilizando la funcion lm() de R, podemos ajustar modelos polinomiales de diferentes grados y comparar el MSE.

```{r}
# Regresión polinomial para diferentes grados
grados <- 1:5  # Probaremos con grados 1 a 5
mse_polynomial <- numeric(length(grados))

for (grado in grados) {
  modelo_pol <- lm(rendimiento ~ poly(lluvia, grado), data = train_data)
  predicciones_pol <- predict(modelo_pol, newdata = train_data)
  mse_polynomial[grado] <- calcular_mse(train_data$rendimiento, predicciones_pol)
}

cat("MSE para diferentes grados: \n")
print(mse_polynomial)

```

A medida que aumentas el grado, el MSE disminuye hasta que se estabiliza en alrededor de 2.79 para grados 3, 4 y 5. Esto sugiere que un polinomio de grado 3 es probablemente el más adecuado, ya que logra un MSE bajo sin agregar demasiada complejidad adicional al modelo.

Usar un grado mayor (como 4 o 5) no mejora significativamente el MSE en comparación con el grado 3, por lo que sería innecesario añadir esa complejidad extra al modelo.

## Hallar el valor de $\lambda$ óptimo para la regresión polinomial de grado 5 con regularización.

En la regresión polinomial con regularización, aplicamos el valor de λλ para controlar la penalización sobre los coeficientes. La fórmula de Ridge es

$$
\text{Minimizar} \left( \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 + \lambda \sum_{j=1}^{d} \beta_j^2 \right)
$$

Donde:

    yiyi​ son los valores observados.
    y^iy^​i​ son los valores predichos.
    λλ es el parámetro de regularización.

```{r}
# Cargar la biblioteca glmnet
library(glmnet)

# Crear matriz de características para el polinomio de grado 5 en los datos de entrenamiento
x_train <- as.matrix(poly(train_data$lluvia, 5, raw = TRUE))
y_train <- train_data$rendimiento                 # Variable dependiente

# Crear matriz de características para los datos de validación
x_validacion <- as.matrix(poly(validacion_data$lluvia, 5, raw = TRUE))

# Ajustar el modelo de Ridge (regresión L2) para un polinomio de grado 5
modelo_ridge <- glmnet(x_train, y_train, alpha = 0, lambda = 0.1)

# Predicciones en los datos de validación
predicciones_ridge <- predict(modelo_ridge, newx = x_validacion)

# Calcular el MSE para Ridge
mse_ridge <- calcular_mse(validacion_data$rendimiento, predicciones_ridge)

# Imprimir el MSE para Ridge
cat("MSE para Ridge con lambda = 0.1: ", mse_ridge, "\n")



```

El MSE de 5.724188 refleja el desempeño del modelo en el conjunto de validación. Es una medida que captura tanto el ajuste del modelo a los datos de entrenamiento como su capacidad para generalizar a nuevos datos. Un MSE más bajo generalmente indica que el modelo está prediciendo mejor los resultados en el conjunto de validación.

Este MSE es útil para comparar la calidad de diferentes modelos o configuraciones, pero por sí solo no dice si el modelo está funcionando "bien" o "mal". Dependerá del contexto de tu problema y de si este MSE es satisfactorio para el uso que se le quiere dar al modelo.

MSE de 5.724188 te da una idea de la precisión del modelo con un polinomio de grado 5 y te permite tomar decisiones informadas sobre si el modelo necesita ajustes o si es adecuado para el propósito de tu análisis.

# Ejercicio 6: Árbol de decisión para clasificar variedades de tomates

| Dulzor | No. tomates | Cherry	| Perita |
|--------|-------------|--------|--------|
| Alto 	 |     55      |	 30	  |  25    |
| Bajo	 |     35	     |   15	  |  20    |


| Dulzor  | No. tomates | Cherry	| Perita |
|---------|-------------|---------|--------|
| Pequeño |     60      |	 40	    |  20    |
| Grande	|     30	    |   5	    |  25    |


## Calcule la impureza de Gini esperada para cada una de las divisiones

La impureza de Gini esperada para una división se calcula como:

$$
\frac{N(t_L)}{N(t)}\times H(y;S_L)+\frac{N(t_R)}{N(t)}\times H(y;S_R)
$$

donde $N(t_L)$ es el número de observaciones en el nodo izquierdo
    $N(t_R)$ es el número de observaciones en el nodo derecho
    $H(y; S_L)$ y $H(y; S_R)$ son las impurezas de Gini de los nodos izquierdo y derecho, respectivamente.

Calculamos la impureza de Gini esperada para cada division. El Gini esperado para la division de Dulzor es

```{r}
# Tamaño de cada nodo
N_root <- 90
N_Alto <- 55
N_Bajo <- 35

# Calcular impurezas de Gini para cada nodo hoja
Gini_Alto <- 1 - ((30 / 55)^2 + (25 / 55)^2)
Gini_Bajo <- 1 - ((15 / 35)^2 + (20 / 35)^2)

# Gini esperado para la división por Dulzor
Gini_Dulzor <- (N_Alto / N_root) * Gini_Alto + (N_Bajo / N_root) * Gini_Bajo
Gini_Dulzor

```

El Gini esperado para la division de tamaño es

```{r}
# Tamaño de cada nodo
N_Pequeno <- 60
N_Grande <- 30

# Calcular impurezas de Gini para cada nodo hoja
Gini_Pequeno <- 1 - ((40 / 60)^2 + (20 / 60)^2)
Gini_Grande <- 1 - ((5 / 30)^2 + (25 / 30)^2)

# Gini esperado para la división por Tamaño
Gini_Tamano <- (N_Pequeno / N_root) * Gini_Pequeno + (N_Grande / N_root) * Gini_Grande
Gini_Tamano

```


```{r}
library(dplyr)
library(rpart)       # Para construir árboles de decisión
library(rpart.plot)  # Para graficar árboles de decisión

# Crear un dataframe con los datos
datos <- data.frame(
  Atributo = rep(c("Dulzor_Alto", "Dulzor_Bajo", "Tamano_Pequeno", "Tamano_Grande"), each = 2),
  Clase = c("Cherry", "Perita", "Cherry", "Perita", "Cherry", "Perita", "Cherry", "Perita"),
  Count = c(30, 25, 15, 20, 40, 20, 5, 25)
)

# Datos para árbol de decisión con Dulzor
dulzor_tree <- rpart(Clase ~ Atributo, data = datos %>% filter(Atributo %in% c("Dulzor_Alto", "Dulzor_Bajo")), weights = Count, method = "class")

# Graficar el árbol de decisión para Dulzor
rpart.plot(dulzor_tree, type = 4, extra = 101, main = "Árbol de decisión basado en Dulzor")

# Datos para árbol de decisión con Tamaño
tamano_tree <- rpart(Clase ~ Atributo, data = datos %>% filter(Atributo %in% c("Tamano_Pequeno", "Tamano_Grande")), weights = Count, method = "class")

# Graficar el árbol de decisión para Tamaño
rpart.plot(tamano_tree, type = 4, extra = 101, main = "Árbol de decisión basado en Tamaño")


```