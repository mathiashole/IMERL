---
title: "ENTREGA 2"
date: today
date-format: "DD MMMM, YYYY"
author: 
  Mathias
abstract:
    Métodos Estadísticos para la Regresión y la Clasificación
abstractspacing: double
appendix: false
fontfamily: libertine
monofont: inconsolata
monofontoptions: scaled=.95
fontsize: 12pt
geometry: 
  - top=2cm
  - bottom=2cm
  - left=2cm
  - right=2cm
urlcolor: darkblue
highlight-style: arrow
format: 
    pdf:
      toc: true
      number-sections: true
      colorlinks: true
---

# Ejercicio 2

Datos de Entrenamiento

| Lluvia (mm)  | Rendimiento (ton/ha) |
|--------------|----------------------|
| 206          | 29                   |
| 188          | 25                   |
| 219          | 31                   |
| 372          | 25                   |
| 345          | 29                   |
| 231          | 30                   |
| 203          | 26                   |
| 170          | 23                   |
| 55           | 12                   |
| 91           | 15                   |
| 292          | 28                   |
| 141          | 24                   |
| 129          | 23                   |
| 170          | 22                   |
| 324          | 30                   |

Datos de Validación

| Lluvia (mm)  | Rendimiento (ton/ha) |
|--------------|----------------------|
| 213          | 30                   |
| 80           | 16                   |
| 391          | 25                   |
| 250          | 26                   |
| 57           | 9                    |
| 303          | 28                   |
| 263          | 28                   |
| 157          | 25                   |
| 72           | 13                   |
| 157          | 23                   |
| 188          | 26                   |
| 216          | 25                   |
| 362          | 28                   |
| 283          | 33                   |
| 308          | 30                   |

## Correr una regresión lineal para predecir el rendimiento y en función de la lluvia $x$.

La regresión lineal se modela mediante la siguiente ecuación

$$
y = \beta_0 + \beta_1 \cdot x
$$

Donde $y$ es el rendimiento $(ton/ha)$, $x$ es la cantidad de lluvia $(mm)$, $beta_0$ es la intersección y $beta_1$ la pendiente de la recta.

```{r}
# Datos de entrenamiento
train_data <- data.frame(
  lluvia = c(206, 188, 219, 372, 345, 231, 203, 170, 55, 91, 292, 141, 129, 170, 324),
  rendimiento = c(29, 25, 31, 25, 29, 30, 26, 23, 12, 15, 28, 24, 23, 22, 30)
)

# Modelo de regresión lineal
modelo_lineal <- lm(rendimiento ~ lluvia, data = train_data)

# Resumen del modelo
summary(modelo_lineal)
```

El coeficiente de la variable lluvia es $\beta_1 = 0.04345$, siendo en promedio que por cada milimetro de lluvia, se espera un aumento en el rendimiento de $0.04345$ toneladas por hectarea. La intersección $\beta_0 = 15.71595$, en el caso de que la lluvia acumulada sea 0, el modelo predice 15.72 toneladas por hectárea. Asimismo, el $\text{p-value}$ indicando que hay una relacion significativa entre la lluvia y el rendimiento.

## Comparar el MSE en entrenamiento, validación y CV.

El MSE se calcula como $\text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2$, siendo $y_i$ valores observados y $hat{y}_i$ los valores predichos. Entonces 

```{r}

# Datos de validación
validacion_data <- data.frame(
  lluvia = c(213, 80, 391, 250, 57, 303, 263, 157, 72, 157, 188, 216, 362, 283, 308),
  rendimiento = c(30, 16, 25, 26, 9, 28, 28, 25, 13, 23, 26, 25, 28, 33, 30)
)

# Función para calcular el MSE
calcular_mse <- function(observado, predicho) {
  mean((observado - predicho)^2)
}

# Predicciones en el conjunto de entrenamiento y validación
predicciones_train <- predict(modelo_lineal, newdata = train_data)
predicciones_validacion <- predict(modelo_lineal, newdata = validacion_data)

# MSE en entrenamiento y validación
mse_train <- calcular_mse(train_data$rendimiento, predicciones_train)
mse_validacion <- calcular_mse(validacion_data$rendimiento, predicciones_validacion)

cat("MSE en entrenamiento: ", mse_train, "\n")
cat("MSE en validación: ", mse_validacion, "\n")

```

Dado los valores obtenidos con MSE de validación cercano al de entrenamiento, como en este caso, sugiere que el modelo tiene un rendimiento adecuado sin un sobreajuste.

## Determinar el grado óptimo en caso de aplicar una regresión polinomial.

La regresión polinomial se ajusta con la siguiente ecuación $y = \beta_0 + \beta_1 \cdot x + \beta_2 \cdot x^2 + \dots + \beta_d \cdot x^d$. Utilizando la funcion lm() de R, podemos ajustar modelos polinomiales de diferentes grados y comparar el MSE.

```{r}
# Regresión polinomial para diferentes grados
grados <- 1:5  # Probaremos con grados 1 a 5
mse_polynomial <- numeric(length(grados))

for (grado in grados) {
  modelo_pol <- lm(rendimiento ~ poly(lluvia, grado), data = train_data)
  predicciones_pol <- predict(modelo_pol, newdata = train_data)
  mse_polynomial[grado] <- calcular_mse(train_data$rendimiento, predicciones_pol)
}

cat("MSE para diferentes grados: \n")
print(mse_polynomial)

```

A medida que aumentas el grado, el MSE disminuye hasta que se estabiliza en alrededor de 2.79 para grados 3, 4 y 5. Esto sugiere que un polinomio de grado 3 es probablemente el más adecuado, ya que logra un MSE bajo sin agregar demasiada complejidad adicional al modelo.

Usar un grado mayor (como 4 o 5) no mejora significativamente el MSE en comparación con el grado 3, por lo que sería innecesario añadir esa complejidad extra al modelo.

## Hallar el valor de $\lambda$ óptimo para la regresión polinomial de grado 5 con regularización.

En la regresión polinomial con regularización, aplicamos el valor de λλ para controlar la penalización sobre los coeficientes. La fórmula de Ridge es

$$
\text{Minimizar} \left( \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 + \lambda \sum_{j=1}^{d} \beta_j^2 \right)
$$

Donde:

    yiyi​ son los valores observados.
    y^iy^​i​ son los valores predichos.
    λλ es el parámetro de regularización.

```{r}
# Cargar la biblioteca glmnet
library(glmnet)

# Crear matriz de características para el polinomio de grado 5 en los datos de entrenamiento
x_train <- as.matrix(poly(train_data$lluvia, 5, raw = TRUE))
y_train <- train_data$rendimiento                 # Variable dependiente

# Crear matriz de características para los datos de validación
x_validacion <- as.matrix(poly(validacion_data$lluvia, 5, raw = TRUE))

# Ajustar el modelo de Ridge (regresión L2) para un polinomio de grado 5
modelo_ridge <- glmnet(x_train, y_train, alpha = 0, lambda = 0.1)

# Predicciones en los datos de validación
predicciones_ridge <- predict(modelo_ridge, newx = x_validacion)

# Calcular el MSE para Ridge
mse_ridge <- calcular_mse(validacion_data$rendimiento, predicciones_ridge)

# Imprimir el MSE para Ridge
cat("MSE para Ridge con lambda = 0.1: ", mse_ridge, "\n")



```

El MSE de 5.724188 refleja el desempeño del modelo en el conjunto de validación. Es una medida que captura tanto el ajuste del modelo a los datos de entrenamiento como su capacidad para generalizar a nuevos datos. Un MSE más bajo generalmente indica que el modelo está prediciendo mejor los resultados en el conjunto de validación.

Este MSE es útil para comparar la calidad de diferentes modelos o configuraciones, pero por sí solo no dice si el modelo está funcionando "bien" o "mal". Dependerá del contexto de tu problema y de si este MSE es satisfactorio para el uso que se le quiere dar al modelo.

MSE de 5.724188 te da una idea de la precisión del modelo con un polinomio de grado 5 y te permite tomar decisiones informadas sobre si el modelo necesita ajustes o si es adecuado para el propósito de tu análisis.

# Ejercicio 6: Árbol de decisión para clasificar variedades de tomates

| Dulzor | No. tomates | Cherry	| Perita |
|--------|-------------|--------|--------|
| Alto 	 |     55      |	 30	  |  25    |
| Bajo	 |     35	     |   15	  |  20    |


| Dulzor  | No. tomates | Cherry	| Perita |
|---------|-------------|---------|--------|
| Pequeño |     60      |	 40	    |  20    |
| Grande	|     30	    |   5	    |  25    |


## Calcule la impureza de Gini esperada para cada una de las divisiones

La impureza de Gini esperada para una división se calcula como:

$$
\frac{N(t_L)}{N(t)}\times H(y;S_L)+\frac{N(t_R)}{N(t)}\times H(y;S_R)
$$

donde $N(t_L)$ es el número de observaciones en el nodo izquierdo
    $N(t_R)$ es el número de observaciones en el nodo derecho
    $H(y; S_L)$ y $H(y; S_R)$ son las impurezas de Gini de los nodos izquierdo y derecho, respectivamente.

Calculamos la impureza de Gini esperada para cada division. El Gini esperado para la division de Dulzor es

```{r}
# Tamaño de cada nodo
N_root <- 90
N_Alto <- 55
N_Bajo <- 35

# Calcular impurezas de Gini para cada nodo hoja
Gini_Alto <- 1 - ((30 / 55)^2 + (25 / 55)^2)
Gini_Bajo <- 1 - ((15 / 35)^2 + (20 / 35)^2)

# Gini esperado para la división por Dulzor
Gini_Dulzor <- (N_Alto / N_root) * Gini_Alto + (N_Bajo / N_root) * Gini_Bajo
Gini_Dulzor

```

El Gini esperado para la division de tamaño es

```{r}
# Tamaño de cada nodo
N_Pequeno <- 60
N_Grande <- 30

# Calcular impurezas de Gini para cada nodo hoja
Gini_Pequeno <- 1 - ((40 / 60)^2 + (20 / 60)^2)
Gini_Grande <- 1 - ((5 / 30)^2 + (25 / 30)^2)

# Gini esperado para la división por Tamaño
Gini_Tamano <- (N_Pequeno / N_root) * Gini_Pequeno + (N_Grande / N_root) * Gini_Grande
Gini_Tamano

```


## ARBOL
```{r}
library(dplyr)
library(rpart)       # Para construir árboles de decisión
library(rpart.plot)  # Para graficar árboles de decisión
library(rattle)

# Crear un dataframe con los datos
datos <- data.frame(
  Atributo = rep(c("Dulzor_Alto", "Dulzor_Bajo", "Tamano_Pequeno", "Tamano_Grande"), each = 2),
  Clase = c("Cherry", "Perita", "Cherry", "Perita", "Cherry", "Perita", "Cherry", "Perita"),
  Count = c(30, 25, 15, 20, 40, 20, 5, 25)
)

datos$Atributo <- factor(datos$Atributo)
datos$Clase <- factor(datos$Clase)

# Entrenar el árbol de decisión utilizando el argumento 'weights' con la columna Count
arbol <- rpart(
  formula = Clase ~ Atributo,
  data = datos %>% filter(Atributo %in% c("Dulzor_Alto", "Dulzor_Bajo")),
  method = 'class',
  weights = Count,
  control = rpart.control(minsplit = 2, 
                          minbucket = 1, 
                          cp = 0.05)
)

# Graficar el árbol utilizando fancyRpartPlot
png("tree_plot.png", width = 800, height = 600)
fancyRpartPlot(arbol)
dev.off()

```

![Arbol de decision dulzor](tree_plot.png)


```{r}
# Datos para árbol de decisión basado en Tamaño
datos_tamano <- data.frame(
  Tamano = c("Pequeño", "Pequeño", "Grande", "Grande"),
  Clase = c("Cherry", "Perita", "Cherry", "Perita"),
  Count = c(40, 20, 5, 25)
)

# Crear y graficar árbol
tamano_tree <- rpart(Clase ~ Tamano, data = datos_tamano, weights = Count, method = "class")
rpart.plot(tamano_tree, type = 4, extra = 101, main = "Árbol de decisión: Tamaño")

```

## ¿Qué pregunta elegiría en el nodo raíz? Justificar en base a las partes anteriores

Dado que:

    Gini esperado para Dulzor: GiniDulzor=0.4935GiniDulzor​=0.4935
    Gini esperado para Tamaño: GiniTaman˜o=0.3889GiniTaman˜o​=0.3889

Elección de la pregunta en el nodo raíz:

La mejor pregunta en el nodo raíz es:
"¿El tamaño es pequeño o grande?"
Justificación:

    Menor impureza:
    La impureza esperada GiniTaman˜oGiniTaman˜o​ es menor que GiniDulzorGiniDulzor​, lo que indica que el atributo Tamaño produce una división más pura y, por lo tanto, mejor separa las clases (Cherry y Perita).

    Distribución más pura en los nodos hijos:
        División por Tamaño:
            Pequeño: 60 tomates (40 Cherry, 20 Perita). Predicción: Cherry.
            Grande: 30 tomates (5 Cherry, 25 Perita). Predicción: Perita.
        División por Dulzor:
            Alto: 55 tomates (30 Cherry, 25 Perita). Mezcla significativa.
            Bajo: 35 tomates (15 Cherry, 20 Perita). Mezcla significativa.

    Observamos que la división por Tamaño resulta en nodos hijos más homogéneos.

    Optimización de la clasificación:
    Elegir Tamaño como el atributo para dividir maximiza la pureza en los nodos y minimiza la incertidumbre de la clasificación, conforme al criterio de Gini.

## Para el árbol elegido en la parte anterior, calcular el error

Cálculo del error para el árbol seleccionado

El error se calcula como la fracción de observaciones mal clasificadas en el conjunto de entrenamiento.

```{r}
# Supongamos que elegimos Dulzor:
# Nodo Alto: predicción Cherry
# Nodo Bajo: predicción Perita

# Observaciones mal clasificadas
error_dulzor <- (25 + 15) / N_root
error_dulzor

# Para Tamaño:
# Nodo Pequeño: predicción Cherry
# Nodo Grande: predicción Perita

error_tamano <- (20 + 5) / N_root
error_tamano

```

# Ejercicio 3: Análisis de Componentes Principales

En este ejercicio, se realiza un análisis de componentes principales (PCA) sobre una matriz de datos que representa las notas obtenidas por los estudiantes en cinco asignaturas. Los datos están organizados en una tabla donde cada fila corresponde a un estudiante y cada columna a una asignatura:

| Estudiante | Matemática | Física | Música | Dibujo | Id. Español |
|------------|------------|--------|--------|--------|-------------|
| Juan       | 12         | 12     | 10     | 11     | 16          |
| Alina      | 16         | 16     | 16     | 16     | 18          |
| Ana        | 12         | 14     | 22     | 19     | 22          |
| Mónica     | 29         | 29     | 31     | 30     | 16          |
| Daniel     | 28         | 28     | 24     | 24     | 20          |
| Andrés     | 22         | 20     | 11     | 14     | 26          |
| Pedro      | 11         | 14     | 28     | 23     | 20          |
| Valentina  | 26         | 25     | 17     | 19     | 24          |
| Sandra     | 18         | 19     | 25     | 24     | 36          |

### Análisis de Componentes Principales (PCA)

Primero, cargamos los datos en R y realizamos el análisis de componentes principales utilizando la función `prcomp`. Esta función nos permite obtener los componentes principales y evaluar la importancia de cada uno.

```{r}
# Datos de las notas de los estudiantes
datos <- data.frame(
  Matemática = c(12, 16, 12, 29, 28, 22, 11, 26, 18),
  Física = c(12, 16, 14, 29, 28, 20, 14, 25, 19),
  Música = c(10, 16, 22, 31, 24, 11, 28, 17, 25),
  Dibujo = c(11, 16, 19, 30, 24, 14, 23, 19, 24),
  `Id. Español` = c(16, 18, 22, 16, 20, 26, 20, 24, 36)
)

# Realizar PCA
pca <- prcomp(datos, scale. = TRUE)

# Mostrar el resumen del PCA
summary(pca)
```

Calidades de cada componente

La "calidad" de cada componente principal se refiere a la varianza explicada por ese componente. La función summary() nos muestra cuánta varianza es explicada por cada uno de los componentes principales.

La varianza explicada por el componente ii se calcula como:
Varianza explicada del componente i=λi∑j=1pλj
Varianza explicada del componente i=∑j=1p​λj​λi​​

donde λiλi​ es el valor propio (eigenvalue) del componente ii y pp es el número total de componentes.
Contribuciones de cada variable

Las contribuciones de cada variable a los componentes principales se pueden obtener examinando las cargas (loadings) de los componentes, que indican qué tan influyente es cada variable en cada componente.
```{r}
# Cargas (loadings) de los componentes
pca$rotation
```

Calidades y contribuciones de los individuos

Finalmente, las coordenadas de cada individuo en el espacio de los componentes principales nos indican en qué medida cada estudiante contribuye a los componentes principales. Estas coordenadas se obtienen multiplicando la matriz de datos centrados y escalados por las cargas de los componentes.
```{r}
# Coordenadas de los individuos en los componentes principales
pca$x
```

Los valores obtenidos nos permiten visualizar la distribución de los estudiantes en el espacio de los componentes principales, mostrando qué tan lejos o cerca están de los ejes principales.
Visualización de los resultados

Podemos visualizar los primeros dos componentes principales utilizando un gráfico de dispersión.
```{r}
# Graficar los primeros dos componentes principales
library(ggplot2)
pca_data <- as.data.frame(pca$x)
pca_data$Estudiante <- c("Juan", "Alina", "Ana", "Mónica", "Daniel", "Andrés", "Pedro", "Valentina", "Sandra")

ggplot(pca_data, aes(x = PC1, y = PC2, label = Estudiante)) +
  geom_point() +
  geom_text(vjust = 1.5, hjust = 1.5) +
  labs(title = "PCA: Primeros dos Componentes Principales", x = "Componente Principal 1", y = "Componente Principal 2")
```

Conclusiones

El análisis de componentes principales nos permite reducir la dimensionalidad del conjunto de datos, extrayendo los componentes que explican la mayor parte de la varianza. En este caso, los componentes principales nos muestran cómo se distribuyen los estudiantes según sus calificaciones en las distintas asignaturas, ayudándonos a identificar patrones o grupos dentro del conjunto de datos.